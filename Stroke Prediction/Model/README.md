**GOAL**

The goal is to predict Stroke of a person.

Dataset can be downloaded from [here](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)

**WHAT I HAD DONE**
- Discussed some major columns on which Stroke depends.
- Handling outliers of diagnosis columns. As, it is very important because at last we're predicting strokes.
- Then I used different classification models present in sklearn to train the model.
- Use Correlation coefficients to measure how strong a relationship is between two variables.

**MODELS USED**
-  Logistic Regression
-  Support Vector Machine (SVM)
-  Decission Tree
-  K Nearest Neighbour
-  Naive Bayes
-  Random Forest Classifier

**LIBRARIES NEEDED**
- numpy
- pandas
- seaborn
- matplotlib
- scikit-learn
- imblearn

**CONCLUSION**
By using Logistic Regression I got 
 ```
    Accuracy of training data: 77.61372705506784
    Accuracy of testing data: 78.56382978723404
 ``` 
 
 By using Support Vector Machine (SVM) I got 
 ```
    Accuracy of training data: 77.6536312849162
    Accuracy of testing data: 78.67021276595744
 ``` 
 
 By using Decission Tree I got 
 ```
    Accuracy of training data: 100.0
    Accuracy of testing data: 94.36170212765957
 ``` 
 
 By using K Nearest Neighbour I got 
 ```
    Accuracy of training data: 93.82814578345304
    Accuracy of testing data: 90.79787234042553
 ``` 
 
 By using Naive Bayes I got 
 ```
    Accuracy of training data: 77.64032987496675
    Accuracy of testing data: 77.55319148936171
 ``` 
 
 By using Random Forest Classifier I got 
 ```
    Accuracy of training data: 100.0
    Accuracy of testing data: 97.3404255319149
 ``` 



<a href="https://github.com/Jagannath8">Jagannath Pal</a>
