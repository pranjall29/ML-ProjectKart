{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:white;font-family:rockwell;font-size:290%;text-align:center\">Sarcasm Detection</h1>\n",
    "\n",
    "*********************************************************\n",
    "\n",
    "![](sar1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "* [**Abstract**](#abstract)\n",
    "* [**Dataset**](#dataset)\n",
    "* [**Importing Dataset and the required libraries**](#import)\n",
    "* [**Visualizing the Target distribution**](#graph)\n",
    "* [**Data Cleaning and Pre-processing**](#cleaning)\n",
    "* [**Classification Algorithms**](#part-b)\n",
    "    * [Spliting the dataset](#train-test-split)\n",
    "    * [Logistic Regression](#log)\n",
    "    * [Random Forest Classifier](#rfc)\n",
    "    * [Convolution Neural Network](#cnn)\n",
    "* [**Conclusion**](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Sarcasm detection is a very narrow research field in NLP, a specific case of sentiment analysis where instead of detecting a sentiment in the whole spectrum, the focus is on sarcasm. Therefore the task of this field is to detect if a given text is sarcastic or not.\n",
    "\n",
    "This dataset is large compared to the other datasets, yet very small compared to the datasets used in DL models. It is imbalanced, meaning there are more non-sarcastic tweets than sarcastic, which is realistic since sarcasm is very rare in our daily interactions and datasets should represent reality as best as they can. And regarding the type of sarcasm, this dataset captures intended sarcasm, this tweet is labelled as sarcastic because the author wants it to be, it doesn’t consider people’s perception.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'dataset'></a>\n",
    "### Dataset\n",
    "The dataset which is used in this project, is collected from Kaggle. Here is the link of the dataset : https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection?select=Sarcasm_Headlines_Dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'import'></a>\n",
    "### Importing the Dataset and the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:30.414294Z",
     "iopub.status.busy": "2021-05-23T06:12:30.412772Z",
     "iopub.status.idle": "2021-05-23T06:12:30.430740Z",
     "shell.execute_reply": "2021-05-23T06:12:30.429970Z",
     "shell.execute_reply.started": "2021-05-23T05:33:25.125511Z"
    },
    "papermill": {
     "duration": 0.049112,
     "end_time": "2021-05-23T06:12:30.430912",
     "exception": false,
     "start_time": "2021-05-23T06:12:30.381800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n",
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:30.490212Z",
     "iopub.status.busy": "2021-05-23T06:12:30.489629Z",
     "iopub.status.idle": "2021-05-23T06:12:38.551589Z",
     "shell.execute_reply": "2021-05-23T06:12:38.551046Z",
     "shell.execute_reply.started": "2021-05-23T05:33:29.566089Z"
    },
    "papermill": {
     "duration": 8.09314,
     "end_time": "2021-05-23T06:12:38.551725",
     "exception": false,
     "start_time": "2021-05-23T06:12:30.458585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Huber, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:38.612141Z",
     "iopub.status.busy": "2021-05-23T06:12:38.611487Z",
     "iopub.status.idle": "2021-05-23T06:12:56.984933Z",
     "shell.execute_reply": "2021-05-23T06:12:56.983758Z",
     "shell.execute_reply.started": "2021-05-23T05:33:44.913981Z"
    },
    "papermill": {
     "duration": 18.407694,
     "end_time": "2021-05-23T06:12:56.985108",
     "exception": false,
     "start_time": "2021-05-23T06:12:38.577414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Collecting en_core_web_md==2.3.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz (50.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 50.8 MB 7.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_md==2.3.1) (2.3.5)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.7.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.25.1)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.2)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.56.2)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.19.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.7.4.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.26.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.12.5)\r\n",
      "Building wheels for collected packages: en-core-web-md\r\n",
      "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for en-core-web-md: filename=en_core_web_md-2.3.1-py3-none-any.whl size=50916640 sha256=3ad116d0cc53af141dc7339b20fb7c67f02ea16d44def9cde919438b62d95933\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-33lk8rnv/wheels/43/1d/c1/a0af68d0648debf57f875e9dda56bbac35cfc27bfa187ffc46\r\n",
      "Successfully built en-core-web-md\r\n",
      "Installing collected packages: en-core-web-md\r\n",
      "Successfully installed en-core-web-md-2.3.1\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_md')\r\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "! python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data distribution into two parts, for the better using purposes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:57.141779Z",
     "iopub.status.busy": "2021-05-23T06:12:57.141042Z",
     "iopub.status.idle": "2021-05-23T06:12:57.489333Z",
     "shell.execute_reply": "2021-05-23T06:12:57.488308Z",
     "shell.execute_reply.started": "2021-05-23T05:35:32.808271Z"
    },
    "papermill": {
     "duration": 0.418209,
     "end_time": "2021-05-23T06:12:57.489543",
     "exception": false,
     "start_time": "2021-05-23T06:12:57.071334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "\n",
    "data_v1 = list(parse_data('/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json'))\n",
    "data_v2 = list(parse_data('/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding the labels as `text` and `Label`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:57.592539Z",
     "iopub.status.busy": "2021-05-23T06:12:57.590899Z",
     "iopub.status.idle": "2021-05-23T06:12:57.593069Z",
     "shell.execute_reply": "2021-05-23T06:12:57.593506Z",
     "shell.execute_reply.started": "2021-05-23T05:35:43.903522Z"
    },
    "papermill": {
     "duration": 0.055446,
     "end_time": "2021-05-23T06:12:57.593636",
     "exception": false,
     "start_time": "2021-05-23T06:12:57.538190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe(list_of_dicts):\n",
    "    all_headlines = [i['headline'] for i in list_of_dicts]\n",
    "    all_labels = [i['is_sarcastic'] for i in list_of_dicts]\n",
    "    return pd.DataFrame({\"Text\":all_headlines, \"Label\":all_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing the data into test and training set of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:57.731219Z",
     "iopub.status.busy": "2021-05-23T06:12:57.729949Z",
     "iopub.status.idle": "2021-05-23T06:12:57.735169Z",
     "shell.execute_reply": "2021-05-23T06:12:57.734740Z",
     "shell.execute_reply.started": "2021-05-23T05:35:54.867237Z"
    },
    "papermill": {
     "duration": 0.096838,
     "end_time": "2021-05-23T06:12:57.735295",
     "exception": false,
     "start_time": "2021-05-23T06:12:57.638457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = create_dataframe(data_v1)\n",
    "test_df = create_dataframe(data_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:57.848557Z",
     "iopub.status.busy": "2021-05-23T06:12:57.847107Z",
     "iopub.status.idle": "2021-05-23T06:12:57.851076Z",
     "shell.execute_reply": "2021-05-23T06:12:57.850466Z",
     "shell.execute_reply.started": "2021-05-23T05:36:07.059759Z"
    },
    "papermill": {
     "duration": 0.068241,
     "end_time": "2021-05-23T06:12:57.851249",
     "exception": false,
     "start_time": "2021-05-23T06:12:57.783008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  Label\n",
      "0  former versace store clerk sues over secret 'b...      0\n",
      "1  the 'roseanne' revival catches up to our thorn...      0\n",
      "2  mom starting to fear son's web series closest ...      1\n",
      "3  boehner just wants wife to listen, not come up...      1\n",
      "4  j.k. rowling wishes snape happy birthday in th...      0\n",
      "                                                Text  Label\n",
      "0  thirtysomething scientists unveil doomsday clo...      1\n",
      "1  dem rep. totally nails why congress is falling...      0\n",
      "2  eat your veggies: 9 deliciously different recipes      0\n",
      "3  inclement weather prevents liar from getting t...      1\n",
      "4  mother comes pretty close to using word 'strea...      1\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape of the Training Dataset and Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:57.959317Z",
     "iopub.status.busy": "2021-05-23T06:12:57.957567Z",
     "iopub.status.idle": "2021-05-23T06:12:57.961490Z",
     "shell.execute_reply": "2021-05-23T06:12:57.961014Z",
     "shell.execute_reply.started": "2021-05-23T05:36:28.094603Z"
    },
    "papermill": {
     "duration": 0.060062,
     "end_time": "2021-05-23T06:12:57.961633",
     "exception": false,
     "start_time": "2021-05-23T06:12:57.901571",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26709, 2) (28619, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate the training and testing set into a single data frame for the model deployment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:58.067973Z",
     "iopub.status.busy": "2021-05-23T06:12:58.065974Z",
     "iopub.status.idle": "2021-05-23T06:12:58.070837Z",
     "shell.execute_reply": "2021-05-23T06:12:58.071294Z",
     "shell.execute_reply.started": "2021-05-23T05:36:40.307803Z"
    },
    "papermill": {
     "duration": 0.062416,
     "end_time": "2021-05-23T06:12:58.071459",
     "exception": false,
     "start_time": "2021-05-23T06:12:58.009043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55328, 2)\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([train_df, test_df], axis=0)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'graph'></a>\n",
    "### Visualizing the Target Distribution\n",
    "Data visualization is a technique that uses an array of static and interactive visuals within a specific context to help people understand and make sense of large amounts of data. The data is often displayed in a story format that visualizes patterns, trends and correlations that may otherwise go unnoticed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:58.175373Z",
     "iopub.status.busy": "2021-05-23T06:12:58.174755Z",
     "iopub.status.idle": "2021-05-23T06:12:58.314912Z",
     "shell.execute_reply": "2021-05-23T06:12:58.315330Z",
     "shell.execute_reply.started": "2021-05-23T05:37:12.498126Z"
    },
    "papermill": {
     "duration": 0.196167,
     "end_time": "2021-05-23T06:12:58.315543",
     "exception": false,
     "start_time": "2021-05-23T06:12:58.119376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Target Distribution')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Label', data=all_data);\n",
    "plt.title('Target Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049081,
     "end_time": "2021-05-23T06:12:58.414921",
     "exception": false,
     "start_time": "2021-05-23T06:12:58.365840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = 'cleaning'></a>\n",
    "### Data Cleaning and Data Preprocessing\n",
    "Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:58.518304Z",
     "iopub.status.busy": "2021-05-23T06:12:58.517485Z",
     "iopub.status.idle": "2021-05-23T06:12:58.520843Z",
     "shell.execute_reply": "2021-05-23T06:12:58.520420Z",
     "shell.execute_reply.started": "2021-05-23T05:38:44.112443Z"
    },
    "papermill": {
     "duration": 0.057481,
     "end_time": "2021-05-23T06:12:58.520952",
     "exception": false,
     "start_time": "2021-05-23T06:12:58.463471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "  \n",
    "  #x = re.sub(r\"\\W\", \" \", x)\n",
    "  x = re.sub(r\"[0-9]\", \" \", x)\n",
    "  x = re.sub(r\"\\s{2,}\", \" \", x)\n",
    "  return x.strip()\n",
    "\n",
    "def clean_text2(x):\n",
    "  \n",
    "  #x = re.sub(r\"\\W\", \" \", x)\n",
    "  #x = re.sub(r\"[0-9]\", \" \", x)\n",
    "  x = re.sub(r\"\\s{2,}\", \" \", x)\n",
    "  x = re.sub(r\" s \", \" \", x)\n",
    "  \n",
    "  return x.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:58.634263Z",
     "iopub.status.busy": "2021-05-23T06:12:58.632621Z",
     "iopub.status.idle": "2021-05-23T06:12:58.634840Z",
     "shell.execute_reply": "2021-05-23T06:12:58.635274Z",
     "shell.execute_reply.started": "2021-05-23T05:38:55.135078Z"
    },
    "papermill": {
     "duration": 0.062169,
     "end_time": "2021-05-23T06:12:58.635412",
     "exception": false,
     "start_time": "2021-05-23T06:12:58.573243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_clean_text = [clean_text2(clean_text(i)) for i in all_data['Text'].tolist()]\n",
    "all_clean_text = all_data['Text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-b\"></a>\n",
    "## Classification Algorithms\n",
    "A classification model tries to draw some conclusion from the input values given for training. It will predict the class labels/categories for the new data.\n",
    "\n",
    "Here we are going to prepare several Classification machine learning models based on those we will do a comparative analysis that which model is better among them.\n",
    "\n",
    "A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, either organic or artificial in nature. Neural networks can adapt to changing input; so the network generates the best possible result without needing to redesign the output criteria. The concept of neural networks, which has its roots in artificial intelligence, is swiftly gaining popularity in the development of trading systems.\n",
    "\n",
    "Mainly I have used the Logistic Regression and Random Forest Classifier and a Sequential model which is Convolution Neural Network.\n",
    "\n",
    "We are using three different classification algorithms -\n",
    "* **Random Forest Classifier** : Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.\n",
    "\n",
    "\n",
    "* **Logistic Regression** : Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n",
    "\n",
    "\n",
    "* **Convolution Neural Network of CNN** : In deep learning, a convolutional neural network (CNN/ConvNet) is a class of deep neural networks, most commonly applied to analyze visual imagery. Now when we think of a neural network we think about matrix multiplications but that is not the case with ConvNet. It uses a special technique called Convolution. Now in mathematics convolution is a mathematical operation on two functions that produces a third function that expresses how the shape of one is modified by the other.\n",
    "\n",
    "Let's quickly get into the algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:12:58.900706Z",
     "iopub.status.busy": "2021-05-23T06:12:58.880103Z",
     "iopub.status.idle": "2021-05-23T06:13:01.067792Z",
     "shell.execute_reply": "2021-05-23T06:13:01.066805Z",
     "shell.execute_reply.started": "2021-05-23T05:39:28.020309Z"
    },
    "papermill": {
     "duration": 2.280227,
     "end_time": "2021-05-23T06:13:01.067925",
     "exception": false,
     "start_time": "2021-05-23T06:12:58.787698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=1000, min_df=10, ngram_range=(2, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(2, 3), max_df=1000, min_df=10)\n",
    "tfidf.fit(all_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:13:01.208014Z",
     "iopub.status.busy": "2021-05-23T06:13:01.202919Z",
     "iopub.status.idle": "2021-05-23T06:13:02.396953Z",
     "shell.execute_reply": "2021-05-23T06:13:02.396452Z",
     "shell.execute_reply.started": "2021-05-23T05:39:40.789862Z"
    },
    "papermill": {
     "duration": 1.281474,
     "end_time": "2021-05-23T06:13:02.397075",
     "exception": false,
     "start_time": "2021-05-23T06:13:01.115601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_feats = tfidf.transform(all_clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train-test-split\"></a>\n",
    "**Training and Testing Dataset Spliting using the `train_test_split`**\n",
    "  \n",
    "  * Immporting the library from the sklearn.model_selection\n",
    "  * Split the training dataset into 60:40 ratio\n",
    "  * name the distributed training dataset as, trainx and trainy.\n",
    "  * Split the testing dataset into 50:50 ratio.\n",
    "  * name the distributed testing dataset as testx and testy.\n",
    "  * testvalx and testvaly are the validation trainning datasets\n",
    "  * valx and valy are the validation testing datasets\n",
    "  * After the spliting of the datasets the model is ready to be prepared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:13:02.506712Z",
     "iopub.status.busy": "2021-05-23T06:13:02.505981Z",
     "iopub.status.idle": "2021-05-23T06:13:02.531336Z",
     "shell.execute_reply": "2021-05-23T06:13:02.530906Z",
     "shell.execute_reply.started": "2021-05-23T05:40:04.188466Z"
    },
    "papermill": {
     "duration": 0.087189,
     "end_time": "2021-05-23T06:13:02.531453",
     "exception": false,
     "start_time": "2021-05-23T06:13:02.444264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainx, testvalx, trainy, testvaly = train_test_split(tfidf_feats, all_data['Label'].tolist(), test_size=0.4)\n",
    "valx, testx, valy, testy = train_test_split(testvalx, testvaly, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'log'></a>\n",
    "### Logistic Regression\n",
    " Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:13:02.638219Z",
     "iopub.status.busy": "2021-05-23T06:13:02.636352Z",
     "iopub.status.idle": "2021-05-23T06:13:03.084489Z",
     "shell.execute_reply": "2021-05-23T06:13:03.083851Z",
     "shell.execute_reply.started": "2021-05-23T05:40:18.881978Z"
    },
    "papermill": {
     "duration": 0.505629,
     "end_time": "2021-05-23T06:13:03.084647",
     "exception": false,
     "start_time": "2021-05-23T06:13:02.579018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10)\n",
    "lr.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:13:03.192140Z",
     "iopub.status.busy": "2021-05-23T06:13:03.191295Z",
     "iopub.status.idle": "2021-05-23T06:13:03.213037Z",
     "shell.execute_reply": "2021-05-23T06:13:03.212315Z",
     "shell.execute_reply.started": "2021-05-23T05:40:32.654717Z"
    },
    "papermill": {
     "duration": 0.080478,
     "end_time": "2021-05-23T06:13:03.213226",
     "exception": false,
     "start_time": "2021-05-23T06:13:03.132748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Score: 0.7623350804265318\n",
      "Test Set Score: 0.7565515994939455\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation Set Score: {lr.score(valx, valy)}\")\n",
    "print(f\"Test Set Score: {lr.score(testx, testy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'rfc'></a>\n",
    "### Random Forest Classifier\n",
    "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:13:03.330168Z",
     "iopub.status.busy": "2021-05-23T06:13:03.328985Z",
     "iopub.status.idle": "2021-05-23T06:14:39.475483Z",
     "shell.execute_reply": "2021-05-23T06:14:39.474773Z",
     "shell.execute_reply.started": "2021-05-23T05:41:02.875621Z"
    },
    "papermill": {
     "duration": 96.205727,
     "end_time": "2021-05-23T06:14:39.475692",
     "exception": false,
     "start_time": "2021-05-23T06:13:03.269965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Score: 0.7969455991324779\n",
      "Test Set Score: 0.7958611964576179\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(trainx, trainy)\n",
    "print(f\"Validation Set Score: {rf.score(valx, valy)}\")\n",
    "print(f\"Test Set Score: {rf.score(testx, testy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048199,
     "end_time": "2021-05-23T06:14:39.573423",
     "exception": false,
     "start_time": "2021-05-23T06:14:39.525224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = 'cnn'></a>\n",
    "### Convolution Neural Network (CNN)\n",
    "There are three types of layers that make up the CNN which are the convolutional layers, pooling layers, and fully-connected (FC) layers. When these layers are stacked, a CNN architecture will be formed.\n",
    "> 1. **Convolution Layer** :This layer is the first layer that is used to extract the various features from the input images.\n",
    "> 2. **Pooling Layer** : The primary aim of this layer is to decrease the size of the convolved feature map to reduce the computational costs.\n",
    "> 3. **Fully Connected Layer** : The Fully Connected (FC) layer consists of the weights and biases along with the neurons and is used to connect the neurons between two different layers.\n",
    "> 4. **Dropout** : Dit decides which information of the model should fire in the forward direction and which ones should not at the end of the network.ropout layer is utilised wherein a few neurons are dropped from the neural network during training process resulting in reduced size of the model.\n",
    "> 5. **Activation Functions** : It decides which information of the model should fire in the forward direction and which ones should not at the end of the network.\n",
    "\n",
    "![](cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:14:39.675958Z",
     "iopub.status.busy": "2021-05-23T06:14:39.675265Z",
     "iopub.status.idle": "2021-05-23T06:17:44.140724Z",
     "shell.execute_reply": "2021-05-23T06:17:44.140020Z",
     "shell.execute_reply.started": "2021-05-23T05:43:04.604442Z"
    },
    "papermill": {
     "duration": 184.519183,
     "end_time": "2021-05-23T06:17:44.140906",
     "exception": false,
     "start_time": "2021-05-23T06:14:39.621723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-23 06:14:40--  http://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\r\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\r\n",
      "--2021-05-23 06:14:40--  https://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\r\n",
      "--2021-05-23 06:14:40--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\r\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 862182613 (822M) [application/zip]\r\n",
      "Saving to: ‘glove.6B.zip’\r\n",
      "\r\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.21MB/s    in 2m 43s  \r\n",
      "\r\n",
      "2021-05-23 06:17:23 (5.05 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:17:45.910773Z",
     "iopub.status.busy": "2021-05-23T06:17:45.909406Z",
     "iopub.status.idle": "2021-05-23T06:18:00.665586Z",
     "shell.execute_reply": "2021-05-23T06:18:00.666191Z",
     "shell.execute_reply.started": "2021-05-23T05:46:12.174394Z"
    },
    "papermill": {
     "duration": 16.404269,
     "end_time": "2021-05-23T06:18:00.666381",
     "exception": false,
     "start_time": "2021-05-23T06:17:44.262112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Size:  400000\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained GloVe embeddings\n",
    "dict_w2v = {}\n",
    "with open('glove.6B.100d.txt', \"r\") as file:\n",
    "    for line in file:\n",
    "        tokens = line.split()\n",
    "        word = tokens[0]\n",
    "        vector = np.array(tokens[1:], dtype=np.float32)\n",
    "        if vector.shape[0] == 100:\n",
    "            dict_w2v[word] = vector\n",
    "        else:\n",
    "            print(\"There was an issue with \" + word)\n",
    "# let's check the vocabulary size\n",
    "print(\"Dictionary Size: \", len(dict_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:00.906829Z",
     "iopub.status.busy": "2021-05-23T06:18:00.904989Z",
     "iopub.status.idle": "2021-05-23T06:18:00.907419Z",
     "shell.execute_reply": "2021-05-23T06:18:00.907820Z",
     "shell.execute_reply.started": "2021-05-23T05:46:28.899665Z"
    },
    "papermill": {
     "duration": 0.12473,
     "end_time": "2021-05-23T06:18:00.907947",
     "exception": false,
     "start_time": "2021-05-23T06:18:00.783217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_WORDS = 10000\n",
    "NUM_CLS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:01.184867Z",
     "iopub.status.busy": "2021-05-23T06:18:01.164193Z",
     "iopub.status.idle": "2021-05-23T06:18:01.802524Z",
     "shell.execute_reply": "2021-05-23T06:18:01.802021Z",
     "shell.execute_reply.started": "2021-05-23T05:46:28.905787Z"
    },
    "papermill": {
     "duration": 0.778176,
     "end_time": "2021-05-23T06:18:01.802659",
     "exception": false,
     "start_time": "2021-05-23T06:18:01.024483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(all_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:02.038251Z",
     "iopub.status.busy": "2021-05-23T06:18:02.037662Z",
     "iopub.status.idle": "2021-05-23T06:18:02.043634Z",
     "shell.execute_reply": "2021-05-23T06:18:02.043000Z",
     "shell.execute_reply.started": "2021-05-23T05:46:29.784619Z"
    },
    "papermill": {
     "duration": 0.125139,
     "end_time": "2021-05-23T06:18:02.043788",
     "exception": false,
     "start_time": "2021-05-23T06:18:01.918649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38246\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = len(tokenizer.word_index) + 1\n",
    "print(NUM_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning the dataset and preparing for the model fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:02.281184Z",
     "iopub.status.busy": "2021-05-23T06:18:02.280389Z",
     "iopub.status.idle": "2021-05-23T06:18:02.359967Z",
     "shell.execute_reply": "2021-05-23T06:18:02.359255Z",
     "shell.execute_reply.started": "2021-05-23T05:46:29.792984Z"
    },
    "papermill": {
     "duration": 0.200853,
     "end_time": "2021-05-23T06:18:02.360149",
     "exception": false,
     "start_time": "2021-05-23T06:18:02.159296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unknown words:  13190\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((NUM_WORDS, embedding_dim))\n",
    "\n",
    "unk_cnt = 0\n",
    "unk_set = set()\n",
    "for word in tokenizer.word_index.keys():\n",
    "    embedding_vector = dict_w2v.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        tkn_id = tokenizer.word_index[word]\n",
    "        embedding_matrix[tkn_id] = embedding_vector\n",
    "    else:\n",
    "        unk_cnt += 1\n",
    "        unk_set.add(word)\n",
    "# Print how many weren't found\n",
    "print(\"Total unknown words: \", unk_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:02.623943Z",
     "iopub.status.busy": "2021-05-23T06:18:02.613789Z",
     "iopub.status.idle": "2021-05-23T06:18:03.714823Z",
     "shell.execute_reply": "2021-05-23T06:18:03.714363Z",
     "shell.execute_reply.started": "2021-05-23T05:46:29.904262Z"
    },
    "papermill": {
     "duration": 1.239717,
     "end_time": "2021-05-23T06:18:03.714950",
     "exception": false,
     "start_time": "2021-05-23T06:18:02.475233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_sequences = tokenizer.texts_to_sequences(all_clean_text)\n",
    "all_padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(all_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train-test-split\"></a>\n",
    "**Training and Testing Dataset Spliting using the `train_test_split`**\n",
    "  \n",
    "  * Immporting the library from the sklearn.model_selection\n",
    "  * Split the training dataset into 60:40 ratio\n",
    "  * name the distributed training dataset as, trainx and trainy.\n",
    "  * Split the testing dataset into 50:50 ratio.\n",
    "  * name the distributed testing dataset as testx and testy.\n",
    "  * testvalx and testvaly are the validation trainning datasets\n",
    "  * valx and valy are the validation testing datasets\n",
    "  * After the spliting of the datasets the model is ready to be prepared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:03.977246Z",
     "iopub.status.busy": "2021-05-23T06:18:03.976354Z",
     "iopub.status.idle": "2021-05-23T06:18:04.003646Z",
     "shell.execute_reply": "2021-05-23T06:18:04.004085Z",
     "shell.execute_reply.started": "2021-05-23T05:46:30.941691Z"
    },
    "papermill": {
     "duration": 0.171004,
     "end_time": "2021-05-23T06:18:04.004273",
     "exception": false,
     "start_time": "2021-05-23T06:18:03.833269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x, valtest_x, train_y, valtest_y = train_test_split(all_padded_sequences, np.asarray(all_data['Label'].tolist(), dtype=np.int32), test_size=0.4)\n",
    "val_x, test_x, val_y, test_y = train_test_split(valtest_x, valtest_y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:04.253951Z",
     "iopub.status.busy": "2021-05-23T06:18:04.253225Z",
     "iopub.status.idle": "2021-05-23T06:18:04.256753Z",
     "shell.execute_reply": "2021-05-23T06:18:04.257403Z",
     "shell.execute_reply.started": "2021-05-23T05:46:30.991580Z"
    },
    "papermill": {
     "duration": 0.13,
     "end_time": "2021-05-23T06:18:04.257611",
     "exception": false,
     "start_time": "2021-05-23T06:18:04.127611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33196, 151) (11066, 151) (11066, 151) (11066,) (33196,) (11066,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, val_x.shape, test_x.shape, val_y.shape, train_y.shape, test_y.shape)\n",
    "train_x, train_y = train_x[:(train_x.shape[0]//32)*32, :], train_y[:(train_y.shape[0]//32)*32]\n",
    "val_x, val_y = val_x[:(val_x.shape[0]//32)*32, :], val_y[:(val_y.shape[0]//32)*32]\n",
    "test_x, test_y = test_x[:(test_x.shape[0]//32)*32, :], test_y[:(test_y.shape[0]//32)*32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:04.500843Z",
     "iopub.status.busy": "2021-05-23T06:18:04.500106Z",
     "iopub.status.idle": "2021-05-23T06:18:04.502691Z",
     "shell.execute_reply": "2021-05-23T06:18:04.503157Z",
     "shell.execute_reply.started": "2021-05-23T05:46:31.001902Z"
    },
    "papermill": {
     "duration": 0.125085,
     "end_time": "2021-05-23T06:18:04.503293",
     "exception": false,
     "start_time": "2021-05-23T06:18:04.378208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MergeHiddenStates(tf.keras.layers.Layer):\n",
    "  def __init__(self):\n",
    "    super(MergeHiddenStates, self).__init__()\n",
    "  \n",
    "  def call(self, inputs):\n",
    "    #print(inputs)\n",
    "    states = inputs#[0]\n",
    "    return tf.reduce_mean(states, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Creation using Tensorflow and Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:04.809725Z",
     "iopub.status.busy": "2021-05-23T06:18:04.807900Z",
     "iopub.status.idle": "2021-05-23T06:18:04.833407Z",
     "shell.execute_reply": "2021-05-23T06:18:04.834447Z",
     "shell.execute_reply.started": "2021-05-23T05:46:36.240812Z"
    },
    "papermill": {
     "duration": 0.21688,
     "end_time": "2021-05-23T06:18:04.834640",
     "exception": false,
     "start_time": "2021-05-23T06:18:04.617760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=(train_x.shape[1], ), vocabsize=NUM_WORDS, emb_dim=50, rnn_units=128, batch_size=32):\n",
    "  model = tf.keras.Sequential([\n",
    "                               tf.keras.layers.Embedding(\n",
    "                                   vocabsize,\n",
    "                                   emb_dim,\n",
    "                                   mask_zero=False,\n",
    "                                   batch_input_shape=(batch_size, input_shape[0]),\n",
    "                                   weights=[embedding_matrix], trainable=True\n",
    "                               ),\n",
    "                               tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_units, dropout=0.2, return_sequences=True)),\n",
    "                               MergeHiddenStates(),\n",
    "                               tf.keras.layers.Dropout(0.3),\n",
    "                               tf.keras.layers.Dense(128, activation='relu'),\n",
    "                               tf.keras.layers.Dropout(0.2),\n",
    "                               tf.keras.layers.Dense(NUM_CLS, activation='softmax')\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "def create_model_v2(input_shape=(train_x.shape[1], ), vocabsize=NUM_WORDS, emb_dim=100, rnn_units=128, batch_size=32):\n",
    "  \n",
    "  inp = tf.keras.layers.Input(shape=input_shape, batch_size=batch_size, dtype=tf.int32)\n",
    "  emb_fixed = tf.keras.layers.Embedding(\n",
    "                                    vocabsize,\n",
    "                                    emb_dim,\n",
    "                                    mask_zero=False,\n",
    "                                    batch_input_shape=(batch_size, input_shape[0]),\n",
    "                                    weights=[embedding_matrix], trainable=False)\n",
    "  \n",
    "  emb_train = tf.keras.layers.Embedding(\n",
    "                                    vocabsize,\n",
    "                                    emb_dim,\n",
    "                                    mask_zero=False,\n",
    "                                    batch_input_shape=(batch_size, input_shape[0]),\n",
    "                                    weights=[embedding_matrix], trainable=True)\n",
    "  \n",
    "  rnn_unit = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_units, dropout=0.2, return_sequences=True))\n",
    "  \n",
    "  x1 = emb_fixed(inp)\n",
    "  x2 = emb_train(inp)\n",
    "  x = tf.keras.layers.Concatenate()([x1, x2])\n",
    "  whole_sequence_output = rnn_unit(x)\n",
    "  x = MergeHiddenStates()(whole_sequence_output)\n",
    "  x = tf.keras.layers.Dropout(0.3)(x)\n",
    "  x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "  x = tf.keras.layers.Dropout(0.2)(x)\n",
    "  preds = tf.keras.layers.Dense(NUM_CLS, activation='softmax')(x)\n",
    "  model = tf.keras.Model(inputs=inp, outputs=preds)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:05.211981Z",
     "iopub.status.busy": "2021-05-23T06:18:05.211141Z",
     "iopub.status.idle": "2021-05-23T06:18:08.007362Z",
     "shell.execute_reply": "2021-05-23T06:18:08.006285Z",
     "shell.execute_reply.started": "2021-05-23T05:46:44.771325Z"
    },
    "papermill": {
     "duration": 2.981113,
     "end_time": "2021-05-23T06:18:08.007492",
     "exception": false,
     "start_time": "2021-05-23T06:18:05.026379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(32, 151)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (32, 151, 100)       3824600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (32, 151, 100)       3824600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (32, 151, 200)       0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (32, 151, 256)       253440      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "merge_hidden_states (MergeHidde (32, 256)            0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (32, 256)            0           merge_hidden_states[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (32, 128)            32896       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (32, 128)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (32, 2)              258         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,935,794\n",
      "Trainable params: 4,111,194\n",
      "Non-trainable params: 3,824,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model = create_model()\n",
    "model = create_model_v2()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:08.265992Z",
     "iopub.status.busy": "2021-05-23T06:18:08.265172Z",
     "iopub.status.idle": "2021-05-23T06:18:08.272053Z",
     "shell.execute_reply": "2021-05-23T06:18:08.271637Z",
     "shell.execute_reply.started": "2021-05-23T05:46:56.544243Z"
    },
    "papermill": {
     "duration": 0.138142,
     "end_time": "2021-05-23T06:18:08.272203",
     "exception": false,
     "start_time": "2021-05-23T06:18:08.134061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(loss=loss_obj, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Convolution Neural Network model with the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:18:08.515737Z",
     "iopub.status.busy": "2021-05-23T06:18:08.515081Z",
     "iopub.status.idle": "2021-05-23T06:22:47.205898Z",
     "shell.execute_reply": "2021-05-23T06:22:47.204830Z",
     "shell.execute_reply.started": "2021-05-23T05:46:59.763514Z"
    },
    "papermill": {
     "duration": 278.814835,
     "end_time": "2021-05-23T06:22:47.206049",
     "exception": false,
     "start_time": "2021-05-23T06:18:08.391214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1037/1037 [==============================] - 59s 52ms/step - loss: 0.4886 - accuracy: 0.7497 - val_loss: 0.2423 - val_accuracy: 0.9014\n",
      "Epoch 2/5\n",
      "1037/1037 [==============================] - 55s 53ms/step - loss: 0.1637 - accuracy: 0.9357 - val_loss: 0.1725 - val_accuracy: 0.9388\n",
      "Epoch 3/5\n",
      "1037/1037 [==============================] - 54s 52ms/step - loss: 0.0568 - accuracy: 0.9803 - val_loss: 0.1913 - val_accuracy: 0.9426\n",
      "Epoch 4/5\n",
      "1037/1037 [==============================] - 55s 53ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.2516 - val_accuracy: 0.9396\n",
      "Epoch 5/5\n",
      "1037/1037 [==============================] - 55s 53ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.2449 - val_accuracy: 0.9422\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=32, epochs=5, validation_data=(val_x, val_y), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting the model using the prediction dataset and the validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:22:49.206266Z",
     "iopub.status.busy": "2021-05-23T06:22:49.205027Z",
     "iopub.status.idle": "2021-05-23T06:22:51.803332Z",
     "shell.execute_reply": "2021-05-23T06:22:51.802807Z",
     "shell.execute_reply.started": "2021-05-23T06:10:45.521712Z"
    },
    "papermill": {
     "duration": 3.599791,
     "end_time": "2021-05-23T06:22:51.803470",
     "exception": false,
     "start_time": "2021-05-23T06:22:48.203679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = np.argmax(model.predict(test_x, batch_size=32), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification report of the Convolution Neural Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-23T06:22:53.807547Z",
     "iopub.status.busy": "2021-05-23T06:22:53.806754Z",
     "iopub.status.idle": "2021-05-23T06:22:53.826406Z",
     "shell.execute_reply": "2021-05-23T06:22:53.827019Z",
     "shell.execute_reply.started": "2021-05-23T06:11:08.220558Z"
    },
    "papermill": {
     "duration": 1.019154,
     "end_time": "2021-05-23T06:22:53.827227",
     "exception": false,
     "start_time": "2021-05-23T06:22:52.808073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      5956\n",
      "           1       0.94      0.95      0.94      5084\n",
      "\n",
      "    accuracy                           0.95     11040\n",
      "   macro avg       0.95      0.95      0.95     11040\n",
      "weighted avg       0.95      0.95      0.95     11040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.987096,
     "end_time": "2021-05-23T06:22:57.816476",
     "exception": false,
     "start_time": "2021-05-23T06:22:56.829380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = 'conclusion'></a>\n",
    "## Conclusion and Comparison\n",
    "We have deployed three machine learning algorithms and every algorithm is deployed successfully without any hesitation. We have checked the accuracy of the models based on the accuracy score of each of the models. Now let's take a look at the scores of each models.\n",
    "\n",
    "|Name of the Model|Accuracy Score|\n",
    "|:---:|:---:|\n",
    "|Logistic Regression|0.76|\n",
    "|Random Forest Classifier|0.80|\n",
    "|Convolution Neural Network|0.95|\n",
    "\n",
    "**Comparing all those scores scored by the machine learning algorithms, it is clear that Convolution Neural Network is having the upper hand in case of this dataset and after this, we can use Logistic Regression, Random Forest Classifier which are also having good score as compared to the other deployed algorithms**\n",
    "\n",
    "Best Fitted Models ranking - \n",
    "1. Convolution Neural Network (CNN)\n",
    "2. Random Forest Classifier\n",
    "3. Logistic Regression\n",
    "\n",
    "\n",
    "\n",
    "Hooray!! The models are deployed successfully!\n",
    "\n",
    "\n",
    "### Hope this project will help you! Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 635.762288,
   "end_time": "2021-05-23T06:23:00.815597",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-23T06:12:25.053309",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
