# -*- coding: utf-8 -*-
"""DiamondPricePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11wfbzEkPrOhIiSqu0CXiCpJszNQBy24p

# **Diamond Price Prediction**

# Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn

"""# Reading the Data"""

df = pd.read_csv('/content/diamonds.csv')
df

"""# Understanding the Data"""

df.dtypes

df.shape

df.size

df.columns

df.info()

df.describe()

df.corr()

df.nunique()

df.isnull().any()

from sklearn.preprocessing import LabelEncoder
labelencoding = LabelEncoder()
categories=['cut', 'color',	'clarity']
df[categories]=df[categories].apply(lambda x:labelencoding.fit_transform(x))
df

"""# Visualiztion"""

import missingno as no
no.bar(df, color='lightblue')

sns.heatmap(df.isnull(), yticklabels='False', cmap='Greens')

df1 = df['cut'].value_counts()
plt.pie(df1.values, labels=df1.index, autopct='%0.2f%%')
plt.title('Pecentage of Cut', fontsize=15)
plt.show()

sns.distplot(df['price'], color='red')

plt.hist(df['carat'],bins = 30, color='g')
plt.xlabel('carat')
plt.ylabel('price')
plt.show()

plt.figure(figsize=(14,8))
sns.violinplot(x=df.color, y=df.carat, palette='rainbow')

plt.figure(figsize=(10,5))
sns.stripplot(x=df.clarity, y=df.carat, palette='magma_r')
plt.show()

sns.boxplot(x='clarity',y='price',data=df)
plt.show()

sns.pairplot(df)

plt.figure(figsize=(18,12))
sns.heatmap(df.corr(), yticklabels='auto', annot=True)
plt.show()

"""# Splitting the Data into Dependent and Independent Variables"""

x = df.drop(['cut', 'color',	'clarity', 'price'], axis=1)
y = df["price"]

x.shape

"""# Feature Importance"""

from sklearn.ensemble import ExtraTreesRegressor
model = ExtraTreesRegressor()
model.fit(x,y)
print(model.feature_importances_)

feat_imp = pd.Series(model.feature_importances_, index=x.columns)

feat_imp.nlargest(5).plot(kind='barh')

"""# Training and Testing the Data"""

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, random_state=23)

"""# Linear Regression"""

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = lr.predict(xtrain)
ypred_test = lr.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac1 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac1)

"""## Error"""

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(ytest, ypred_test)
print("Mean Square Error:", mse)

"""# KNN Regressor"""

from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = knn.predict(xtrain)
ypred_test = knn.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac2 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac2)

"""## Error"""

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(ytest, ypred_test)
print("Mean Square Error:", mse)

"""# Decission Tree Regressor"""

from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeRegressor(ccp_alpha=0.1, max_depth=2)
dt.fit(xtrain, ytrain)

"""## Prediction"""

ypred_train = dt.predict(xtrain)
ypred_test = dt.predict(xtest)

"""## Accuracy"""

from sklearn import metrics
print("Accuracy of training data:", metrics.r2_score(ytrain, ypred_train)*100)
ac3 = metrics.r2_score(ytest, ypred_test)*100
print("Accuracy of testing data:", ac3)

"""## Error"""

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(ytest, ypred_test)
print("Mean Square Error:", mse)

accuracy =  {ac1: 'Logistic Regression', ac2: 'KNN', ac3:'Decission Tree'}

sns.set_style('darkgrid')
plt.figure(figsize=(14, 10))
model_accuracies = list(accuracy.values())
model_names = list(accuracy.keys())
sns.barplot(x=model_accuracies, y=model_names, palette='gist_rainbow')

"""# Saving the Model"""

import pickle 
pickle.dump(knn, open('model.pkl', 'wb'))